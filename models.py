# -*- coding: utf-8 -*-
"""DS_504_FP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cQsoiGFbupi36zw7Vhip5--vl7tQX6Np

## Libraries
"""

import numpy as np
import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
# %matplotlib inline

pip install biosppy

pip install PyWavelets

import scipy
from scipy import stats
from scipy import signal
from scipy.stats import f_oneway
from scipy.signal import welch
from scipy.interpolate import interp1d
from scipy.signal import find_peaks
from scipy.signal import iirnotch
from scipy.signal import butter, filtfilt
import biosppy.signals.ecg as ecg
import pywt

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split

pip install --upgrade scikit-learn

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import IsolationForest

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

import os
import sys
import pathlib
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.utils.data import DataLoader, Dataset, TensorDataset
from torchvision.models import vgg16
from torchvision import transforms

import tensorflow as tf
import tensorflow.keras as keras

from keras.preprocessing import sequence
from keras import Sequential
from keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding, Concatenate, Input
from tensorflow.keras.layers import Conv1D, MaxPool1D, BatchNormalization, Activation, GlobalAveragePooling1D, Dense, Dropout
from tensorflow.keras.models import Model, Sequential
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.text import one_hot, Tokenizer
from keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Reshape, Permute
from keras.layers import Flatten, GlobalMaxPool1D, GlobalMaxPooling1D, Conv1D, Convolution1D
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers

# Create a label encoder object
label_encoder = LabelEncoder()

# Initialize the scaler
scaler = MinMaxScaler()

pip install wfdb

pip install ast

import wfdb
import ast

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device

"""## Data"""

from google.colab import files
files.upload()

df = pd.read_csv('df.csv')
df.head(10)

df = pd.read_csv('merged_data_A0001-A0014.csv', sep=';')
df.head(10)

df.shape

df['ID'].value_counts()

df['Abbreviation'].value_counts()

df['Dx'].value_counts()

map = pd.read_csv('SNOMED_mappings_scored.csv', sep=';')
map.head(10)

map.shape

map['Dx'].value_counts()

map_un = pd.read_csv('SNOMED_mappings_unscored.csv', sep=';')
map_un.head(10)

df.info()

df.columns

# Rename the columns
df.rename(columns={'Dx': 'temp', 'SNOMED CT Code': 'Dx', 'temp': 'SNOMED CT Code'}, inplace=True)
df.head()

df.rename(columns={'temp': 'SNOMED CT Code'}, inplace='True')
df.head()

df.shape

df.info()

# Merge the two DataFrames based on 'SNOMED CT Code'
merged_df = df.merge(map_un[['SNOMED CT Code', 'Dx', 'Abbreviation']], on='SNOMED CT Code', how='left')
merged_df.columns

# Fill missing values in 'Dx' and 'Abbreviation' columns with values from the 'map_unscored' DataFrame
merged_df['Dx_y'].fillna(merged_df['Dx_y'], inplace=True)
merged_df['Abbreviation_y'].fillna(merged_df['Abbreviation_y'], inplace=True)

# Drop unnecessary columns
#merged_df.drop(columns=['Dx_y', 'Abbreviation_y'], inplace=True)

# Rename columns if needed
merged_df.rename(columns={'Dx_y': 'Dx', 'Abbreviation_y': 'Abbreviation'}, inplace=True)
merged_df.head()

merged_df.shape

merged_df.info()

# Create a dictionary mapping 'SNOMED CT Code' to 'Dx' and 'Abbreviation' from 'map_unscored' DataFrame
mapping_dict = map_un.set_index('SNOMED CT Code')[['Dx', 'Abbreviation']].to_dict(orient='index')

# Fill missing values in 'Dx' and 'Abbreviation' columns of 'df' using the mapping dictionary
df['Dx'] = df['Dx'].fillna(df['SNOMED CT Code'].map(lambda x: mapping_dict[x]['Dx'] if x in mapping_dict else None))
df['Abbreviation'] = df['Abbreviation'].fillna(df['SNOMED CT Code'].map(lambda x: mapping_dict[x]['Abbreviation'] if x in mapping_dict else None))

df.shape

df.info()

df['Dx'].value_counts()

df.head()

df.to_csv('df.csv', index=False)

"""# EDA

## General

Distribution of Diagnostic Classes (Dx):
Visualize the distribution of diagnostic classes to understand the imbalance, if any, in the dataset. This will help you decide whether any class balancing techniques are necessary during model training.

Age and Sex Distribution:
Explore the distribution of age and sex in the dataset. This can help identify any biases or imbalances in the data based on demographic factors.

Signal Visualization:
Plot the signals (ECG waveforms) for different diagnostic classes to observe any distinguishable patterns. This can provide insights into how the ECG signals vary across different conditions.

Correlation Analysis:
Conduct correlation analysis between the ECG signals and diagnostic classes. Identify which signals are most correlated with specific diagnostic classes. This can guide feature selection for model training.

Age and Sex vs. Diagnostic Classes:
Analyze the relationship between age, sex, and diagnostic classes. Are certain diagnostic classes more prevalent in specific age groups or genders? Visualize this relationship to understand potential demographic factors influencing the diagnosis.

Dimensionality Reduction:
Apply dimensionality reduction techniques like PCA or t-SNE to visualize the high-dimensional ECG signal data in a lower-dimensional space. This can help identify clusters or groupings within the data.

Time-Series Analysis:
Analyze the temporal characteristics of the ECG signals. Explore features such as heart rate variability, QT interval, ST segment changes, etc., and their relationship with diagnostic classes.

Missing Data Analysis:
Investigate the presence of missing data in the dataset and its distribution across different features. Decide on appropriate strategies for handling missing data, such as imputation or exclusion.

Outlier Detection:
Identify outliers or anomalous data points in the dataset. Determine whether these outliers are genuine instances of rare conditions or errors in data collection.

By conducting thorough EDA using these ideas, you'll gain valuable insights into your dataset that can inform the design and optimization of your Deep Learning models for predicting diagnostic classes from ECG signals.
"""

df['ID'].value_counts()

df.describe()

df['Dx'].value_counts()

# Group the data by 'ID' and check if each group has only one unique value of 'Dx'
same_class_per_patient = df.groupby('ID')['Dx'].nunique() == 1

# Print the result
print("Patients with the same class 'Dx' for every row:")
print(same_class_per_patient[same_class_per_patient].index)

# Count the occurrences of each diagnostic class
class_counts = df['Dx'].value_counts()

# Plot the distribution of diagnostic classes
plt.figure(figsize=(10, 6))
sns.countplot(y='Dx', data=df, order=class_counts.index)
plt.title('Distribution of Diagnostic Classes (Dx)')
plt.xlabel('Count')
plt.ylabel('Diagnostic Class')
plt.show()

# Extract unique patients (unique 'ID' values) along with their corresponding age and sex
unique_patients = df.drop_duplicates(subset='ID')[['ID', 'Age', 'Sex']]

# Plot the distribution of age
plt.figure(figsize=(6, 4))
sns.histplot(data=unique_patients, x='Age', bins=20, kde=True)
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

# Plot the distribution of sex
plt.figure(figsize=(6, 4))
sns.countplot(data=unique_patients, x='Sex')
plt.title('Distribution of Sex')
plt.xlabel('Sex')
plt.ylabel('Count')
plt.show()

# Select a subset of the dataset for each diagnostic class
diagnostic_classes = ['atrial fibrillation', 'st depression', 'ventricular ectopics',
                      'left bundle branch block', 'right bundle branch block', 'sinus rhythm']

# Plot ECG waveforms for each diagnostic class
plt.figure(figsize=(12, 8))
for i, diagnostic_class in enumerate(diagnostic_classes, 1):
    plt.subplot(3, 2, i)
    class_subset = df[df['Dx'] == diagnostic_class].sample(n=1)  # Select a random sample for each class
    signals = class_subset.drop(columns=['ID', 'Age', 'Sex', 'SNOMED CT Code', 'Dx', 'Abbreviation']).values.flatten()
    plt.plot(signals)
    plt.title(diagnostic_class)
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')
plt.tight_layout()
plt.show()

# Encode the 'Dx' column into numerical labels
df['Dx_encoded'] = label_encoder.fit_transform(df['Dx'])
df['Dx_encoded'].head()

df.info()

# Calculate correlation coefficients between ECG signals and diagnostic class labels
correlation_matrix = df.drop(columns=['ID', 'Age', 'Sex', 'SNOMED CT Code', 'Abbreviation']).corrwith(df['Dx_encoded'])

# Sort correlation coefficients in descending order
sorted_correlation = correlation_matrix.abs().sort_values(ascending=False)

# Print the top correlated signals with diagnostic class labels
print("Top correlated signals with diagnostic class labels:")
print(sorted_correlation.head(10))

# Select numerical columns (ECG signals) and the 'Dx' column
numerical_columns = df.drop(columns=['ID', 'Age', 'Sex', 'SNOMED CT Code', 'Abbreviation', 'Dx'])

# Initialize an empty dictionary to store ANOVA results
anova_results = {}

# Perform ANOVA for each numerical column
for column in numerical_columns:
    # Perform one-way ANOVA test
    anova_result = f_oneway(*[numerical_columns[column][df['Dx'] == diagnostic_class] for diagnostic_class in df['Dx'].unique()])
    # Store the F-statistic and p-value in the dictionary
    anova_results[column] = {'F-statistic': anova_result.statistic, 'p-value': anova_result.pvalue}

# Print ANOVA results
for column, result in anova_results.items():
    print(f"ANOVA for {column}: F-statistic = {result['F-statistic']}, p-value = {result['p-value']}")

# Create a DataFrame with unique patients along with their age, sex, and diagnostic class
unique_patients = df.drop_duplicates(subset='ID')[['ID', 'Age', 'Sex', 'Dx']]

# Pivot the DataFrame to create a matrix with age, sex, and diagnostic class as indices
pivot_table = unique_patients.pivot_table(index='Dx', columns=['Age', 'Sex'], aggfunc='size', fill_value=0)

# Plot a heatmap to visualize the relationship between age, sex, and diagnostic classes
plt.figure(figsize=(12, 8))
sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt='g', linewidths=0.5)
plt.title('Relationship between Age, Sex, and Diagnostic Classes')
plt.xlabel('Age and Sex')
plt.ylabel('Diagnostic Class')
plt.show()

"""## ECG Signals

Certainly! Here are some additional exploratory data analysis (EDA) ideas related to ECG signals:

Frequency Domain Analysis:
Perform spectral analysis (e.g., Fourier transform) to decompose ECG signals into frequency components.
Visualize power spectral density (PSD) and identify dominant frequency bands.
Analyze frequency domain features (e.g., LF/HF ratio) and their relationship with diagnostic classes.

Beat Detection and Heart Rate Variability (HRV):
Implement algorithms for beat detection to identify R peaks in ECG signals.
Calculate RR intervals and derive HRV metrics such as SDNN, RMSSD, and pNN50.
Explore temporal patterns of HRV metrics and their correlation with diagnostic classes.

Waveform Morphology Analysis:
Segment ECG signals into individual heartbeats and extract morphological features (e.g., amplitude, duration, slope) of P, QRS, and T waves.
Compare waveform morphology across different diagnostic classes and identify characteristic patterns.

Temporal Trends and Variability:
Analyze temporal trends and variability in ECG signals over different time periods (e.g., hours, days).
Identify circadian rhythms and investigate their influence on ECG characteristics.

Artifact Detection and Correction:
Develop algorithms to detect and correct artifacts in ECG signals (e.g., baseline drift, muscle noise, electrode movement).
Evaluate the impact of artifact removal techniques on signal quality and diagnostic accuracy.

Cross-Correlation Analysis:
Perform cross-correlation analysis between pairs of ECG signals to assess their similarity or lagged relationships.
Explore patterns of lead-to-lead correlation and their implications for diagnostic interpretation.

Temporal Dynamics of Abnormal Events:
Identify abnormal events (e.g., arrhythmias, ST segment changes) in ECG signals using anomaly detection algorithms.
Analyze the temporal dynamics of abnormal events and their association with clinical outcomes.

Deep Learning-Based Feature Extraction:
Train deep learning models (e.g., convolutional neural networks, recurrent neural networks) to automatically extract discriminative features from ECG signals.
Visualize learned representations and interpret their relevance to diagnostic classes.

Longitudinal Analysis:
Conduct longitudinal analysis of ECG signals from individual patients to track changes over time.
Investigate disease progression, treatment effects, and prognostic markers using longitudinal data.

Interactive Visualization Tools:
Develop interactive visualization tools for exploring ECG signals, allowing users to zoom, pan, and annotate specific segments.
Integrate interactive features for real-time signal processing and analysis.

By exploring these EDA ideas, you can gain deeper insights into the characteristics of ECG signals and their relationship with clinical diagnoses, ultimately contributing to improved understanding and patient care.
"""

# Extract signal data
signals = df.drop(columns=['ID', 'Age', 'Sex', 'SNOMED CT Code', 'Dx', 'Abbreviation'])
signals.columns

# Plot each signal as a wave
plt.figure(figsize=(12, 6))
for signal in signals.columns:
    plt.plot(signals.index, signals[signal], label=signal)

# Add labels and title
plt.xlabel('Time')
plt.ylabel('Amplitude')
plt.title('ECG Signals')
plt.legend()
plt.show()

# Plot each signal individually
plt.figure(figsize=(20, 16))
for i, signal in enumerate(signals.columns, 1):
    plt.subplot(len(signals.columns), 1, i)
    plt.plot(signals.index, signals[signal])
    plt.title(signal)
    plt.xlabel('Time')
    plt.ylabel('Amplitude')
plt.tight_layout()
plt.show()

# Calculate the length of each ECG signal
signal_lengths = df.drop(columns=['ID', 'Age', 'Sex', 'SNOMED CT Code', 'Dx', 'Abbreviation', 'Dx_encoded']).apply(lambda x: len(x.dropna()))

# Plot the distribution of signal lengths
plt.figure(figsize=(10, 6))
plt.hist(signal_lengths, bins=50, color='skyblue', edgecolor='black')
plt.title('Distribution of Signal Lengths')
plt.xlabel('Signal Length')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

"""## Frequency Domain Analysis

Performing frequency domain analysis on ECG signals involves decomposing the signals into their frequency components using techniques such as Fourier transform. Here's how you can perform frequency domain analysis and analyze its relationship with diagnostic classes:

Fourier Transform:
Apply Fourier transform to convert the ECG signals from the time domain to the frequency domain.
Calculate the power spectral density (PSD) to represent the distribution of signal power across different frequencies.
You can use libraries like NumPy or SciPy in Python to compute the Fourier transform and PSD.

Visualization of PSD:
Plot the PSD of ECG signals to visualize the frequency content of the signals.
Identify dominant frequency bands and peaks in the PSD that correspond to physiological phenomena such as heart rate and respiratory rate.
Matplotlib or seaborn can be used to create visualizations of the PSD.

Frequency Domain Features:
Extract frequency domain features such as low frequency (LF) and high frequency (HF) components from the PSD.
Calculate the LF/HF ratio, which is a measure of sympathovagal balance in the autonomic nervous system.
These features provide insights into the underlying physiological mechanisms and may be related to specific diagnostic classes.

Relationship with Diagnostic Classes:
Analyze the relationship between frequency domain features (e.g., LF/HF ratio) and diagnostic classes.
Use statistical tests or visualization techniques such as box plots or scatter plots to compare frequency domain features across different diagnostic classes.
Determine if certain diagnostic classes are associated with distinct frequency characteristics in ECG signals.

Here's a general outline of the steps involved in performing frequency domain analysis and analyzing its relationship with diagnostic classes.
"""

# Create a list of signal column names
signal_columns = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']

# Extract the ECG signal data from column 'I' and convert it to a NumPy array
sample_signal = np.array(df['I'])

# Sampling rate of the ECG signals (in Hz)
sampling_rate = 1000  # Assuming a sampling rate of 1000 Hz

print("Sample signal data:", sample_signal)

# Function to compute power spectral density (PSD)
def compute_psd(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, nperseg=1024)
    return f, Pxx

# Compute PSD of the sample signal
frequencies, psd = compute_psd(sample_signal, sampling_rate)

# Plot the PSD
plt.figure(figsize=(10, 6))
plt.plot(frequencies, psd)
plt.title('Power Spectral Density (PSD) of ECG Signal')
plt.xlabel('Frequency (Hz)')
plt.ylabel('Power')
plt.grid(True)
plt.show()

# Plot PSD for each signal
plt.figure(figsize=(10, 6))
for signal_column in signal_columns:
    # Extract the ECG signal data from the DataFrame and convert it to a NumPy array
    sample_signal = np.array(df[signal_column])

    # Compute PSD of the sample signal
    frequencies, psd = compute_psd(sample_signal, sampling_rate)

    # Plot the PSD
    plt.plot(frequencies, psd, label=signal_column)

plt.title('Power Spectral Density (PSD) of ECG Signals')
plt.xlabel('Frequency (Hz)')
plt.ylabel('Power')
plt.legend(loc='upper right')
plt.grid(True)
plt.show()

def compute_lfhf_ratio(frequencies, psd):
    # Define frequency bands for LF and HF components
    lf_band = np.logical_and(frequencies >= 0.04, frequencies <= 0.15)
    hf_band = np.logical_and(frequencies >= 0.15, frequencies <= 0.4)

    # Calculate LF and HF powers using trapezoidal integration
    lf_power = np.trapz(psd[lf_band], frequencies[lf_band])
    hf_power = np.trapz(psd[hf_band], frequencies[hf_band])

    # Check if HF power is zero
    if hf_power == 0:
        # Handle the case when HF power is zero (division by zero)
        # You can return a default value, such as NaN or None
        return np.nan

    # Compute LF/HF ratio
    return lf_power / hf_power

# Initialize an empty list to store LF-HF ratios for each signal
lfhf_ratios = []

# Compute LF/HF ratios for each signal
lfhf_ratios = []
for signal_column in signal_columns:
    # Extract the ECG signal data from the DataFrame and convert it to a NumPy array
    sample_signal = np.array(df[signal_column])

    # Compute PSD of the sample signal
    frequencies, psd = compute_psd(sample_signal, sampling_rate)

    # Compute LF/HF ratio
    lfhf_ratio = compute_lfhf_ratio(frequencies, psd)

    # Append the computed LF/HF ratio to the list
    lfhf_ratios.append(lfhf_ratio)

# Add LF/HF ratios to the DataFrame
#df['LF/HF Ratio'] = lfhf_ratios

# Print LF/HF ratios for debugging
print("LF/HF Ratios:", lfhf_ratios)

# Compute LF/HF ratio
lfhf_ratios = [compute_lfhf_ratio(frequencies, psd) for frequencies, psd in zip(all_frequencies, all_psds)]

# Print LF/HF ratios for debugging
print("LF/HF Ratios:", lfhf_ratios)

# Plot LF/HF ratio distribution across diagnostic classes
plt.figure(figsize=(8, 6))
plt.boxplot([df[df['Dx'] == dx]['LF/HF Ratio'] for dx in df['Dx'].unique()], labels=df['Dx'].unique())
plt.title('LF/HF Ratio Distribution Across Diagnostic Classes')
plt.xlabel('Diagnostic Class')
plt.ylabel('LF/HF Ratio')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

"""## Beat Detection & HRV

To implement beat detection and calculate heart rate variability (HRV) metrics from ECG signals, follow these steps:

Beat Detection: Implement a beat detection algorithm to identify R peaks in the ECG signals. Common approaches include threshold-based methods, template matching, and machine learning techniques.

RR Interval Calculation: Compute RR intervals (time intervals between successive R peaks) from the detected R peaks. This forms the basis for HRV analysis.

HRV Metrics Calculation:
SDNN (Standard Deviation of NN Intervals): Calculate the standard deviation of RR intervals, which reflects overall HRV.
RMSSD (Root Mean Square of Successive Differences): Compute the square root of the mean of the squares of the differences between successive RR intervals, which reflects short-term HRV.

pNN50 (Percentage of NN50 Intervals): Determine the percentage of RR intervals that differ by more than 50 ms from the previous interval, which is another measure of short-term HRV.

Explore Temporal Patterns: Analyze the temporal patterns of HRV metrics across different diagnostic classes. Visualize how these metrics vary over time and their correlation with diagnostic labels.
"""

def detect_r_peaks(ecg_signal, threshold=0.6, window_size=100):
    """
    Detect R peaks in ECG signal using a simple threshold-based approach.

    Parameters:
        ecg_signal (array-like): ECG signal data.
        threshold (float): Threshold value for peak detection.
        window_size (int): Size of the window for local peak detection.

    Returns:
        r_peaks (array): Indices of detected R peaks.
    """
    # Smooth the signal using a moving average filter
    smoothed_signal = np.convolve(ecg_signal, np.ones(window_size) / window_size, mode='same')

    # Find peaks above the threshold
    peaks = np.where(smoothed_signal > threshold)[0]

    # Find local maxima as R peaks
    r_peaks = []
    for i in range(1, len(peaks) - 1):
        if smoothed_signal[peaks[i]] > smoothed_signal[peaks[i - 1]] and smoothed_signal[peaks[i]] > smoothed_signal[peaks[i + 1]]:
            r_peaks.append(peaks[i])

    return np.array(r_peaks)

# Example usage:
# Generate synthetic ECG signal
t = np.linspace(0, 10, 1000)
ecg_signal = np.sin(2 * np.pi * 1 * t) + 0.5 * np.sin(2 * np.pi * 10 * t)

# Detect R peaks
r_peaks = detect_r_peaks(ecg_signal)

# Plot the ECG signal and detected R peaks
plt.figure(figsize=(12, 6))
plt.plot(t, ecg_signal, label='ECG Signal')
plt.scatter(t[r_peaks.astype(int)], ecg_signal[r_peaks.astype(int)], color='red', label='Detected R Peaks')
plt.xlabel('Time')
plt.ylabel('Amplitude')
plt.title('ECG Signal with Detected R Peaks')
plt.legend()
plt.grid(True)
plt.show()

# Generate or load ECG signal data
ecg_signal = np.array(df[signal_columns])  # Replace ... with your ECG signal data
sampling_rate = 1000

ecg_signal = ecg_signal.flatten()

# Time array corresponding to the ECG signal
t = np.arange(len(ecg_signal)) / sampling_rate

# Apply peak detection algorithm
r_peaks, _ = find_peaks(ecg_signal, height=None, distance=None)

# Plot the ECG signal with detected R peaks
plt.figure(figsize=(12, 6))
plt.plot(t, ecg_signal, label='ECG Signal')
plt.scatter(t[r_peaks], ecg_signal[r_peaks], color='red', label='Detected R Peaks')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.title('ECG Signal with Detected R Peaks')
plt.legend()
plt.grid(True)
plt.show()

# Step 2: Compute RR intervals (time differences between successive R peaks)
rr_intervals = np.diff(r_peaks)

# Convert the indices to time intervals (assuming a constant sampling rate)
# sampling_rate is the sampling rate of your ECG signal
# Convert to milliseconds by dividing by the sampling rate and multiplying by 1000
rr_intervals_ms = rr_intervals / sampling_rate * 1000

# Now rr_intervals_ms contains the RR intervals in milliseconds

# Step 3: Calculate HRV metrics
# SDNN (Standard Deviation of NN Intervals)
sdnn = np.std(rr_intervals_ms)

# RMSSD (Root Mean Square of Successive Differences)
rmssd = np.sqrt(np.mean(np.square(np.diff(rr_intervals_ms))))

# pNN50 (Percentage of NN50 Intervals)
nn50_count = np.sum(np.abs(np.diff(rr_intervals)) > 50)
pnn50 = np.sum(np.diff(rr_intervals_ms) > 50) / len(rr_intervals_ms) * 100

# Assign diagnostic labels
df['SDNN'] = sdnn
df['RMSSD'] = rmssd
df['pNN50'] = pnn50

# Visualize temporal patterns

# Example line plot of HRV metrics over time for each diagnostic class
plt.figure(figsize=(10, 6))
sns.lineplot(data=df.reset_index(), x=df.index, y='SDNN', hue='Dx')
plt.title('Temporal Patterns of SDNN Across Diagnostic Classes')
plt.xlabel('Time')
plt.ylabel('SDNN')
plt.legend(title='Diagnostic Class')
plt.show()

# Calculate correlation coefficients
# Example correlation analysis between HRV metrics and diagnostic labels
corr_matrix = df[['SDNN', 'RMSSD', 'pNN50', 'Dx']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix between HRV Metrics and Diagnostic Labels')
plt.show()

"""## Wave Morphology Analysis

To perform waveform morphology analysis, you'll need to segment ECG signals into individual heartbeats and then extract morphological features of the P, QRS, and T waves. Here's a general outline of the steps involved:

Segmentation: Segment the ECG signal into individual heartbeats using R peak detection or other heartbeat segmentation methods.

Feature Extraction: Extract morphological features of the P, QRS, and T waves from each segmented heartbeat. These features may include amplitude, duration, slope, area under the curve, etc.

Comparison Across Diagnostic Classes: Compare the waveform morphology features across different diagnostic classes to identify characteristic patterns or differences.
"""

# List of column names containing the ECG signal data
signal_columns = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']

# Segmentation

# Dictionary to store ECG signal data for each column
ecg_signals = {}

# Loop through each column and store the ECG signal data
for column in signal_columns:
    ecg_signals[f'ecg_signal_{column}'] = df[column].values

# R peak detection to segment the ECG signal into individual heartbeats
r_peaks, _ = ecg.hamilton_segmenter(ecg_signal)

# Check the length of the ECG signal
ecg_signal_length = len(ecg_signal)

# Get the padding length required by the QRS complex detector
padding_length = 15  # This is just an example, replace it with the actual padding length used in the QRS complex detector

# Compare the length of the ECG signal with the padding length
if ecg_signal_length > padding_length:
    print("Length of ECG signal is sufficient for the QRS complex detector.")
else:
    print("Length of ECG signal is not sufficient for the QRS complex detector. Adjust the padding length or acquire more data.")

# Feature Extraction
# Define a function to extract morphological features from each heartbeat
def extract_morphological_features(signal, r_peaks):
    features = []
    for i in range(len(r_peaks) - 1):
        heartbeat = signal[r_peaks[i]:r_peaks[i+1]]
        # Example feature extraction (you can customize this based on your requirements)
        amplitude = np.max(heartbeat) - np.min(heartbeat)
        duration = len(heartbeat)
        slope = np.mean(np.diff(heartbeat))
        features.append({'Amplitude': amplitude, 'Duration': duration, 'Slope': slope})
    return features

# Extract morphological features from each heartbeat
morphological_features = extract_morphological_features(ecg_signal, r_peaks)

# Convert the extracted features into a DataFrame for easy analysis
features_df = pd.DataFrame(morphological_features)

# Step 3: Comparison Across Diagnostic Classes
# Assuming you have a DataFrame named 'df' containing diagnostic classes

# Add a column to the features DataFrame indicating the diagnostic class for each heartbeat
features_df['Diagnostic_Class'] = df['Dx'].iloc[:len(r_peaks)-1].values

# Example: Box plot to compare amplitude across diagnostic classes
plt.figure(figsize=(10, 6))
sns.boxplot(data=features_df, x='Diagnostic_Class', y='Amplitude')
plt.title('Comparison of Amplitude Across Diagnostic Classes')
plt.xlabel('Diagnostic Class')
plt.ylabel('Amplitude')
plt.show()

"""## Cross-Correlation Analysis

Extract the ECG signal data for each lead (e.g., I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6).
Compute the cross-correlation between pairs of ECG signals.
Visualize the cross-correlation results to assess similarity or lagged relationships.

The heatmap will show the strength and direction of the correlation between each pair of leads. Positive values indicate a positive correlation, while negative values indicate a negative correlation. The magnitude of the correlation coefficient indicates the strength of the relationship.
"""

# Extract ECG signal data for each lead
leads = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']
ecg_data = df[leads]

# Compute cross-correlation between pairs of ECG signals
cross_corr_matrix = ecg_data.corr()

# Visualize cross-correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cross_corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Cross-Correlation Matrix of ECG Signals')
plt.xlabel('ECG Leads')
plt.ylabel('ECG Leads')
plt.show()

"""## Temporal Dynamics of Abnormal Events"""

# Initialize isolation forest model
isolation_forest = IsolationForest(contamination=0.01, random_state=42)

# Fit the model to the ECG data
isolation_forest.fit(ecg_data)

# Predict outliers (abnormal events) in the ECG data
outlier_predictions = isolation_forest.predict(ecg_data)

# Add outlier predictions to the DataFrame
df['Abnormal_Event'] = outlier_predictions

# Visualize abnormal events over time for a specific lead (e.g., 'I')
plt.figure(figsize=(12, 6))
plt.plot(df.index, df['I'], label='ECG Signal (Lead I)')
plt.scatter(df.index[df['Abnormal_Event'] == -1], df['I'][df['Abnormal_Event'] == -1], color='red', label='Abnormal Event')
plt.xlabel('Time')
plt.ylabel('Amplitude')
plt.title('Temporal Dynamics of Abnormal Events in ECG Signal (Lead I)')
plt.legend()
plt.show()

"""## Longitudinal Analysis"""

df.head(10)

# Step 1: Group the DataFrame by patient ID
grouped_df = df.groupby('ID')

# Step 2: Extract ECG signals for each patient and perform analysis
for patient_id, patient_data in grouped_df:
    # Extract ECG signals for the patient
    ecg_signals = patient_data[['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']]

    # Step 3: Apply analysis techniques (e.g., waveform morphology analysis, HRV analysis, anomaly detection)
    # For example, you can perform waveform morphology analysis:
    # TODO: Perform waveform morphology analysis

    # Step 4: Visualize longitudinal changes over time for each patient
    plt.figure(figsize=(10, 6))
    for column in ecg_signals.columns:
        plt.plot(patient_data.index, patient_data[column], label=f'ECG Signal ({column})')
    plt.title(f'Longitudinal Analysis of ECG Signals for Patient ID: {patient_id}')
    plt.xlabel('Sample Index')
    plt.ylabel('Amplitude')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  # Adjust legend position
    plt.grid(True)
    plt.show()

"""## Interactive Visualization"""

# Create a Plotly figure
fig = go.Figure()

# Add each ECG signal to the plot
for column in df.columns:
    fig.add_trace(go.Scatter(x=df.index, y=df[column], mode='lines', name=column))

# Update layout with interactive features
fig.update_layout(
    title="Interactive ECG Signal Visualization",
    xaxis_title="Time",
    yaxis_title="Amplitude",
    xaxis=dict(
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1d", step="day", stepmode="backward"),
                dict(count=7, label="1w", step="day", stepmode="backward"),
                dict(count=1, label="1m", step="month", stepmode="backward"),
                dict(step="all")
            ])
        ),
        rangeslider=dict(visible=True),
        type="date"
    )
)

# Show the interactive plot
fig.show()

"""## Temporal Trends and Variability"""

df.columns

df.drop(columns=['LF/HF Ratio (I)', 'LF/HF Ratio (II)', 'LF/HF Ratio (III)',
       'LF/HF Ratio (aVR)', 'LF/HF Ratio (aVL)', 'LF/HF Ratio (aVF)',
       'LF/HF Ratio (V1)', 'LF/HF Ratio (V2)', 'LF/HF Ratio (V3)',
       'LF/HF Ratio (V4)', 'LF/HF Ratio (V5)', 'LF/HF Ratio (V6)'], inplace=True)

df_num = df.drop(columns=['Age', 'Sex', 'SNOMED CT Code', 'Dx', 'Abbreviation', 'SDNN',
       'RMSSD', 'pNN50', 'Abnormal_Event'])

# Group by patient ID and calculate mean signal values for each patient
df_grouped = df_num.groupby('ID').mean()
df_grouped.head()

# Plot temporal trends for each signal for each patient
for signal in df.columns[1:]:  # Exclude 'ID' column
    plt.figure(figsize=(10, 6))
    for patient_id, patient_data in df_grouped.iterrows():
        x = range(len(df.columns[1:]))  # Use range based on number of signals
        y = patient_data.values[1:]  # Exclude the 'ID' column
        plt.plot(x, y, label=patient_id)

    # Add plot labels and title
    plt.xlabel('Signal Index')
    plt.ylabel('Signal Value')
    plt.title(f'Temporal Trends of ECG Signals ({signal})')

    # Show legend
    plt.legend()

    # Show plot
    plt.show()

"""## Artifact Detection and Correction

To develop algorithms for artifact detection and correction in ECG signals, you can employ various techniques. Here's a general approach you can take:

Baseline Drift Detection and Correction: Baseline drift can occur due to various factors such as electrode contact issues or patient movement. You can use techniques like high-pass filtering or polynomial fitting to detect and correct baseline drift.

Muscle Noise Removal: Muscle noise often appears as high-frequency noise in ECG signals. Techniques such as band-stop filtering or wavelet denoising can be used to remove muscle noise while preserving the ECG components.

Electrode Movement Artifact Detection: Sudden shifts in ECG signals can occur due to electrode movement. These artifacts can be detected by analyzing signal variance or using adaptive thresholding techniques. Once detected, you can interpolate or replace the affected segments of the signal.

Power Line Interference Removal: Power line interference, often at 50 Hz or 60 Hz frequencies, can contaminate ECG signals. Notch filtering or adaptive filtering can be applied to remove power line interference.

Outlier Detection and Removal: Outliers in ECG signals may indicate electrode detachment or other anomalies. Statistical methods such as z-score or median filtering can be used to identify and remove outliers.
"""

df.columns

df_signals = df.drop(columns = ['Age', 'Sex', 'SNOMED CT Code', 'Dx', 'Abbreviation',
       'SDNN', 'RMSSD', 'pNN50', 'Abnormal_Event'])

# Baseline drift correction using polynomial fitting
for col in df_signals.columns[1:]:
    df_signals[col] = signal.detrend(df_signals[col], type='linear')

# Power line interference removal using notch filtering
def notch_filter(signal, fs, line_freq):
    nyquist = fs / 2
    freq = line_freq / nyquist
    b, a = signal.iirnotch(freq, Q=30)
    return signal.filtfilt(b, a, signal)

fs = 1000  # Sample rate (replace with your actual sample rate)
line_freq = 60  # Power line frequency (replace with 50 or 60 as applicable)

for col in df_signals.columns[1:]:
    df_signals[col] = notch_filter(df_signals[col], fs, line_freq)

plt.figure(figsize=(10, 6))
for col in df_signals.columns[1:]:
    plt.plot(df_signals[col], label=col)

# Add plot labels and title
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.title('Corrected ECG Signals')
plt.legend(loc='upper right', bbox_to_anchor=(1.25, 1))  # Adjust legend position
plt.show()

def denoise_signal(signal, wavelet='db4', level=1):
    # Remove NaN values from the signal
    signal = signal.dropna()
    coeffs = pywt.wavedec(signal, wavelet, mode='per')
    threshold = np.sqrt(2 * np.log(len(signal)))
    coeffs[1:] = (pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:])
    denoised_signal = pywt.waverec(coeffs, wavelet, mode='per')
    # Pad or trim denoised signal to match the length of the index
    denoised_signal = np.append(denoised_signal, [denoised_signal[-1]])[:len(signal)]
    return denoised_signal

# Apply wavelet denoising to each signal
for col in df_signals.columns[1:]:
    df_signals[col] = denoise_signal(df_signals[col])

plt.figure(figsize=(10, 6))
for col in df_signals.columns[1:]:
    plt.plot(df_signals.index, df_signals[col], label=col)

# Add plot labels and title
plt.xlabel('Time')
plt.ylabel('Amplitude')
plt.title('Denoised ECG Signals')
plt.legend(loc='upper right', bbox_to_anchor=(1.25, 1))  # Adjust legend position
plt.show()

# Step 1: Detect Artifacts
# Calculate variance of each signal
variance = df_signals.iloc[:, 1:].var()

# Step 2: Thresholding
# Define a threshold for detecting artifacts based on variance
threshold = 0.1  # Adjust this threshold based on your data

# Identify segments with variance exceeding the threshold
artifacts = variance[variance > threshold].index

# Step 3: Interpolation or Replacement
# Interpolate or replace the affected segments
for signal in artifacts:
    # Implement your interpolation or replacement technique here
    # For example, you can use linear interpolation:
    df_signals[signal] = df_signals[signal].interpolate(method='linear')

# Visualize the corrected signals
plt.figure(figsize=(10, 6))
for col in df_signals.columns[1:]:
    plt.plot(df_signals[col], label=col)

# Add plot labels and title
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.title('ECG Signals with Corrected Artifact')

# Move the legend outside the plot area
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))

plt.show()

# Step 1: Calculate z-score for each signal
z_scores = df_signals.iloc[:, 1:].apply(lambda x: np.abs(stats.zscore(x)))

# Set a threshold value for z-score to identify outliers
z_score_threshold = 3  # Adjust this threshold based on your data

# Step 2: Identify outliers based on z-score
outliers = z_scores > z_score_threshold

# Step 3: Apply median filtering to smooth the signal
smoothed_signals = df_signals.iloc[:, 1:].apply(lambda x: x.rolling(window=5, min_periods=1).median())

# Identify outliers based on deviation from the smoothed signal
median_filtered_outliers = np.abs(df_signals.iloc[:, 1:] - smoothed_signals) > z_score_threshold

# Visualize the outliers
plt.figure(figsize=(10, 6))

# Plot original signals with outliers
for col in df_signals.columns[1:]:
    plt.plot(df_signals[col], label=col, color='blue', alpha=0.5)

# Highlight outliers detected using z-score
plt.plot(df_signals[outliers].index, df_signals[outliers].values, 'rx', label='Z-score Outliers')

# Highlight outliers detected using median filtering
plt.plot(df_signals[median_filtered_outliers].index, df_signals[median_filtered_outliers].values, 'go', label='Median Filter Outliers')

# Add plot labels and title
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.title('Outlier Detection in ECG Signals')

# Adjust legend position to prevent overlap
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))

plt.show()

"""## Time Series Analysis"""

df_num = df.drop(columns = ['Sex', 'SNOMED CT Code', 'Abbreviation',
       'SDNN', 'RMSSD', 'pNN50', 'Abnormal_Event'])

# Step 1: Calculate temporal characteristics
# For example, you can calculate the mean heart rate for each patient
mean_hr = df_num.groupby('ID').mean()

# Step 2: Visualize the distribution of mean heart rate for each diagnostic class
plt.figure(figsize=(10, 6))
for diagnostic_class in df['Dx'].unique():
    patient_ids = df[df['Dx'] == diagnostic_class]['ID'].unique()
    mean_hr_class = mean_hr.loc[patient_ids, 'I']  # Assuming 'I' column represents heart rate
    plt.hist(mean_hr_class, bins=20, alpha=0.5, label=diagnostic_class)

plt.xlabel('Mean Heart Rate')
plt.ylabel('Frequency')
plt.title('Distribution of Mean Heart Rate for Each Diagnostic Class')
plt.legend()
plt.show()

"""# Feature Engineering

Feature engineering is crucial for extracting relevant information from raw ECG signals to improve predictive modeling. Here are some potential feature engineering techniques you can explore:

Statistical Features: Compute statistical metrics such as mean, median, standard deviation, skewness, kurtosis, minimum, maximum, and percentiles for each ECG lead. These features can capture the distribution and variability of signal amplitudes.

Time-Domain Features: Calculate time-domain features such as heart rate, RR interval, QT interval, QRS duration, PR interval, and ST segment characteristics. These features capture temporal characteristics of the ECG waveform.

Frequency-Domain Features: Apply Fourier or wavelet transforms to extract frequency-domain features such as dominant frequency, spectral power, and frequency band energy. These features provide insights into the frequency composition of the signal.

Heart Rate Variability (HRV) Features: Compute HRV features such as standard deviation of NN intervals (SDNN), root mean square of successive differences (RMSSD), and frequency-domain measures (e.g., LF, HF power) from RR interval time series. HRV features reflect autonomic nervous system activity and can be indicative of cardiovascular health.

Wavelet Transform: Decompose the ECG signal using wavelet transform to extract wavelet coefficients at different scales. These coefficients can be used as features to capture signal details at different resolutions.

Nonlinear Features: Explore nonlinear features such as sample entropy, approximate entropy, and detrended fluctuation analysis (DFA) exponent. These features capture complexity and irregularity in the ECG signal dynamics.

Signal Morphology Features: Analyze signal morphology using techniques such as principal component analysis (PCA) or independent component analysis (ICA) to extract representative features that describe the shape and structure of the ECG waveform.

Ensemble Features: Combine multiple features using ensemble techniques such as feature aggregation (e.g., mean, median) or feature selection algorithms (e.g., recursive feature elimination, feature importance ranking) to create composite features with higher predictive power.

Dynamic Features: Explore dynamic features derived from signal segments or windows, such as moving averages, signal gradients, or time-domain autocorrelation coefficients. These features capture temporal changes and dynamics in the signal.

Clinical Domain Knowledge: Incorporate domain-specific knowledge or expert-derived features relevant to cardiovascular physiology and pathology, such as ST segment elevation/depression, T wave abnormalities, or presence of arrhythmias.

By leveraging these feature engineering techniques, you can extract informative features from raw ECG signals that capture relevant physiological characteristics and improve the predictive performance of machine learning models for diagnosing cardiovascular diseases.

## Statistical Features
"""

df_updated = df
df_updated.columns

df_updated.head(10)

df_updated.info()

df_updated.describe()

df_filtered = df_updated.drop(columns=['ID',	'I',	'II',	'III',	'aVR',	'aVL',	'aVF',	'V1',	'V2',	'V3', 'V4',	'V5',	'V6',	'Age',	'Sex',	'SNOMED CT Code',	'Dx',	'Abbreviation'])
df_filtered.columns

df_updated['Abnormal_Event'].value_counts()

df_updated['SDNN'].value_counts()

df.info()

# Extract ECG signal leads (columns) from the DataFrame
ecg_leads = df[['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']]

# Define a function to compute statistical features for each lead
def compute_statistical_features(signal):
    features = {
        'mean': np.mean(signal),
        'median': np.median(signal),
        'std_dev': np.std(signal),
        'skewness': pd.Series(signal).skew(),
        'kurtosis': pd.Series(signal).kurtosis(),
        'min': np.min(signal),
        'max': np.max(signal),
        'percentile_25': np.percentile(signal, 25),
        'percentile_75': np.percentile(signal, 75)
    }
    return features

# Compute statistical features for each lead
statistical_features = {}
for lead in ecg_leads.columns:
    features = compute_statistical_features(ecg_leads[lead])
    statistical_features[lead] = features

# Convert statistical features dictionary to DataFrame
sf_df = pd.DataFrame(statistical_features).T
sf_df.head()

"""## Time-Domain Features"""

df.columns

def compute_qt_interval(ecg_lead, fs=1000):
    # Compute QT interval as the time duration between the Q wave and the end of the T wave
    # Here, we'll use threshold-based detection to identify the Q and T waves

    # Ensure ecg_lead is a numeric series
    if not pd.api.types.is_numeric_dtype(ecg_lead):
        return None

    # Thresholds for Q and T wave detection (replace with appropriate values based on your signal characteristics)
    q_threshold = 0.2 * ecg_lead.max()
    t_threshold = 0.2 * ecg_lead.max()

    # Find Q wave as the first peak above q_threshold
    q_indices, _ = find_peaks(ecg_lead, height=q_threshold, distance=0.1*fs)
    if len(q_indices) == 0:
        return None  # Unable to detect Q wave

    # Find T wave as the last peak above t_threshold
    reversed_ecg_lead = -ecg_lead  # Invert the signal for finding peaks
    t_indices, _ = find_peaks(reversed_ecg_lead, height=t_threshold, distance=0.1*fs)
    if len(t_indices) == 0:
        return None  # Unable to detect T wave

    # Compute QT interval (in seconds)
    qt_interval = (t_indices[-1] - q_indices[0]) / fs
    return qt_interval

def compute_qrs_duration(ecg_lead, fs=1000):
    # Compute QRS duration as the time duration between the Q and S waves
    # Here, we'll use threshold-based detection to identify the Q and S waves

    # Ensure ecg_lead is a numeric series
    if not pd.api.types.is_numeric_dtype(ecg_lead):
        return None

    # Thresholds for Q and S wave detection (replace with appropriate values based on your signal characteristics)
    q_threshold = 0.2 * ecg_lead.max()
    s_threshold = 0.2 * ecg_lead.max()

    # Find Q wave as the first peak above q_threshold
    q_indices, _ = find_peaks(ecg_lead, height=q_threshold, distance=0.1*fs)
    if len(q_indices) == 0:
        return None  # Unable to detect Q wave

    # Find S wave as the first valley below s_threshold after the Q wave
    s_indices, _ = find_peaks(-ecg_lead[q_indices[0]:], height=s_threshold, distance=0.1*fs)
    if len(s_indices) == 0:
        return None  # Unable to detect S wave

    # Compute QRS duration (in seconds)
    qrs_duration = (s_indices[0] + q_indices[0]) / fs
    return qrs_duration

def bandpass_filter(signal, lowcut, highcut, fs, order=5):
    # Apply a bandpass filter to the signal to remove noise and isolate specific frequency components
    # Use a Butterworth filter for this purpose

    nyquist = 0.5 * fs
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(order, [low, high], btype='band')
    filtered_signal = filtfilt(b, a, signal)
    return filtered_signal

def pan_tompkins_detector(signal, fs):
    # Apply the Pan-Tompkins algorithm to detect the QRS complex in the ECG signal

    # Step 1: Bandpass filtering (Already done)

    # Step 2: Differentiation
    diff_signal = np.diff(signal)

    # Step 3: Squaring
    squared_signal = diff_signal ** 2

    # Step 4: Moving Window Integration
    window_width = int(0.12 * fs)  # 120 ms window
    mwi_signal = np.convolve(squared_signal, np.ones(window_width) / window_width, mode='same')

    # Step 5: Find peaks in the MWI signal
    peaks, _ = find_peaks(mwi_signal, height=0.6*np.max(mwi_signal), distance=0.2*fs)

    return peaks

def compute_pr_interval(ecg_lead, fs=1000):
    # Compute PR interval as the time duration between the P wave and the start of the QRS complex
    # Here, we'll use the Pan-Tompkins algorithm to detect the QRS complex and then identify the P wave
    # This method is more accurate than threshold-based detection

    # Ensure ecg_lead is a numeric series
    if not pd.api.types.is_numeric_dtype(ecg_lead):
        return None

    # Apply bandpass filter to remove noise and isolate QRS complex
    # Replace with your appropriate bandpass filter parameters
    filtered_ecg = bandpass_filter(ecg_lead, lowcut=5, highcut=15, fs=fs)

    # Compute QRS complex using Pan-Tompkins algorithm
    qrs_indices = pan_tompkins_detector(filtered_ecg, fs=fs)
    if len(qrs_indices) == 0:
        return None  # Unable to detect QRS complex

    # Find the P wave before the QRS complex
    # Search for the first peak before the QRS complex
    peaks, _ = find_peaks(ecg_lead[:qrs_indices[0]], height=0.1*np.max(ecg_lead[:qrs_indices[0]]), distance=0.2*fs)
    if len(peaks) == 0:
        return None  # Unable to detect P wave

    # Compute PR interval (in seconds)
    pr_interval = (qrs_indices[0] - peaks[-1]) / fs
    return pr_interval

def find_end_of_s_wave(signal, s_wave_start_index, fs):
    # Given the start index of the S wave, find the end index of the S wave in the ECG signal

    # Assuming the S wave duration is around 80-120 ms
    # Search for the maximum amplitude within the next 100 ms after the start of the S wave
    search_window = int(0.1 * fs)
    s_wave_end_index = s_wave_start_index + np.argmax(signal[s_wave_start_index:s_wave_start_index+search_window])

    # Ensure the end index is within the range of the signal length
    if s_wave_end_index >= len(signal):
        s_wave_end_index = len(signal) - 1

    return s_wave_end_index

def compute_st_segment(ecg_lead, fs=1000):
    # Compute ST segment deviation as the difference in amplitude between the end of the S wave and the TP segment
    # Here, we'll use the end of the S wave and the end of the TP segment as reference points

    # Ensure ecg_lead is a numeric series
    if not pd.api.types.is_numeric_dtype(ecg_lead):
        return None

    # Find the end of the S wave
    # Search for the end of the S wave after the QRS complex
    qrs_indices = pan_tompkins_detector(ecg_lead, fs=fs)
    if len(qrs_indices) == 0:
        return None  # Unable to detect QRS complex
    s_wave_start_index = qrs_indices[-1]

    # Check if s_wave_start_index is within the valid range of the series
    if s_wave_start_index >= len(ecg_lead):
        return None

    s_wave_end_index = find_end_of_s_wave(ecg_lead, s_wave_start_index, fs=fs)

    # Check if s_wave_end_index is within the valid range of the series
    if s_wave_end_index >= len(ecg_lead):
        return None

    # Compute ST segment deviation
    last_value = ecg_lead.iloc[-1] if isinstance(ecg_lead, pd.Series) else ecg_lead[-1]
    st_segment_deviation = ecg_lead.iloc[s_wave_end_index] - last_value
    return st_segment_deviation

# Define a function to compute time-domain features
def compute_time_domain_features(ecg_lead, fs=1000):
    # Convert ECG lead to numeric values
    ecg_lead_numeric = pd.to_numeric(ecg_lead, errors='coerce')

    # Remove NaN values
    ecg_lead_numeric = ecg_lead_numeric.dropna()

    # Compute RR intervals
    rr_intervals = np.diff(np.where(ecg_lead_numeric > 0)[0]) / fs  # Assuming ECG lead is filtered and has positive peaks

    # Compute heart rate (beats per minute)
    heart_rate = 60 / np.mean(rr_intervals)

    # Compute QT interval (in seconds)
    qt_interval = None  # Implement QT interval computation based on your method

    # Compute QRS duration (in seconds)
    qrs_duration = None  # Implement QRS duration computation based on your method

    # Compute PR interval (in seconds)
    pr_interval = None  # Implement PR interval computation based on your method

    # Compute ST segment characteristics (e.g., elevation, depression)
    st_segment = None  # Implement ST segment characteristics computation based on your method

    # Return computed features
    features = {
        'heart_rate': heart_rate,
        'rr_intervals': rr_intervals,
        'qt_interval': qt_interval,
        'qrs_duration': qrs_duration,
        'pr_interval': pr_interval,
        'st_segment': st_segment
    }
    return features

# Compute time-domain features for each lead
time_domain_features = {}
for lead in df.columns[1:]:
    time_domain_features_df.loc[lead, 'qt_interval'] = compute_qt_interval(df[lead])
    time_domain_features_df.loc[lead, 'qrs_duration'] = compute_qrs_duration(df[lead])
    time_domain_features_df.loc[lead, 'pr_interval'] = compute_pr_interval(df[lead])
    time_domain_features_df.loc[lead, 'st_segment'] = compute_st_segment(df[lead])

# Convert time-domain features dictionary to DataFrame
time_domain_features_df = pd.DataFrame(time_domain_features).T
time_domain_features_df.head()

time_domain_features_df.columns

time_domain_features_df.shape

"""# DL

## Prep
"""

df.head(10)

df.info()

df.shape

df['Dx'].value_counts()

df['ID'].value_counts()

# Encode the classes in 'Dx' column
df['Dx_encoded'] = label_encoder.fit_transform(df['Dx'])
df['Dx_encoded'].value_counts()

# Define features (X) and target variable (y)
X = df[['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']]
y = df['Dx_encoded'].values

# Fit the scaler on the training data and transform the data
X_norm = scaler.fit_transform(X)

# Split the data into training (80%), validation (10%), and testing (10%) sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Print the shapes of the resulting datasets
print("X_train shape:", X_train.shape)
print("X_val shape:", X_val.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_val shape:", y_val.shape)
print("y_test shape:", y_test.shape)

# Convert arrays to tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)
X_val = torch.tensor(X_val, dtype=torch.float32)
y_val = torch.tensor(y_val, dtype=torch.long)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.long)

# Create DataLoader
train_data = TensorDataset(X_train, y_train)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)

# Create DataLoader for validation set
val_data = TensorDataset(X_val, y_val)
val_loader = DataLoader(val_data, batch_size=64, shuffle=False)

# Create DataLoader
test_data = TensorDataset(X_test, y_test)
test_loader = DataLoader(test_data, batch_size=64, shuffle=True)

X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)

X_val_tensor = torch.tensor(X_val, dtype=torch.float32)
y_val_tensor = torch.tensor(y_val, dtype=torch.long)

X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.long)

# Create DataLoader for training, validation, and testing sets
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
val_loader = DataLoader(val_dataset, batch_size=64)

test_dataset = TensorDataset(X_test_tensor, y_test_tensor)
test_loader = DataLoader(test_dataset, batch_size=64)

# Initialize the model, loss function, and optimizer
input_size = len(X_train.columns)
hidden_size = 128
num_classes = len(sampled_df['Dx'].unique())

"""## ANN"""

# Define the neural network architecture
class ANN(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(ANN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

model = ANN(input_size, hidden_size, num_classes)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Lists to store training and validation loss and accuracy
train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []

# Training the model
num_epochs = 50
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    correct_train = 0
    total_train = 0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)

        _, predicted_train = torch.max(outputs, 1)
        total_train += labels.size(0)
        correct_train += (predicted_train == labels).sum().item()

    train_losses.append(train_loss/len(train_loader.dataset))
    train_accuracies.append((correct_train/total_train)*100)

    # Validate the model
    model.eval()
    val_loss = 0.0
    correct_val = 0
    total_val = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
            _, predicted_val = torch.max(outputs, 1)
            total_val += labels.size(0)
            correct_val += (predicted_val == labels).sum().item()

    val_losses.append(val_loss/len(val_loader.dataset))
    val_accuracies.append((correct_val/total_val)*100)

    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]}, Train Accuracy: {train_accuracies[-1]:.2f}%, Val Loss: {val_losses[-1]}, Val Accuracy: {val_accuracies[-1]:.2f}%")

# Plotting
plt.figure(figsize=(10, 5))

# Loss plots
plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs + 1), train_losses, label='Train')
plt.plot(range(1, num_epochs + 1), val_losses, label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()

# Accuracy plots
plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train')
plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Evaluate on the test set
model.eval()
test_loss = 0.0
correct_test = 0
total_test = 0
predictions = []
true_labels = []

with torch.no_grad():
    for inputs, labels in test_loader:
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        test_loss += loss.item() * inputs.size(0)
        _, predicted = torch.max(outputs, 1)
        predictions.extend(predicted.tolist())
        true_labels.extend(labels.tolist())
        total_test += labels.size(0)
        correct_test += (predicted == labels).sum().item()

# Calculate metrics
test_accuracy = (correct_test / total_test) * 100
precision = precision_score(true_labels, predictions, average='macro')
recall = recall_score(true_labels, predictions, average='macro')
f1 = f1_score(true_labels, predictions, average='macro')
conf_matrix = confusion_matrix(true_labels, predictions)
class_report = classification_report(true_labels, predictions)

print(f"Test Loss: {test_loss / len(test_loader.dataset)}, Test Accuracy: {test_accuracy:.2f}%")
print(f"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-score: {f1:.2f}")
print("\nConfusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(class_report)

# Normalize confusion matrix
conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

# Plot
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix_normalized, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Normalized Confusion Matrix')
plt.colorbar()
classes = ['0', '1', '2', '3', '4', '5', '6']  # Replace with your class names
plt.xticks(np.arange(len(classes)), classes, rotation=45)
plt.yticks(np.arange(len(classes)), classes)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')

# Display values on the plot
for i in range(conf_matrix_normalized.shape[0]):
    for j in range(conf_matrix_normalized.shape[1]):
        plt.text(j, i, format(conf_matrix_normalized[i, j], '.2f'),
                 ha="center", va="center", color="white" if conf_matrix_normalized[i, j] > 0.5 else "black")

plt.tight_layout()
plt.show()

"""## FCN"""

class SimpleFCN(nn.Module):
    def __init__(self):
        super(SimpleFCN, self).__init__()
        self.fc1 = nn.Linear(12, 64)  # Input layer with 12 features
        self.relu = nn.ReLU()         # Activation function
        self.fc2 = nn.Linear(64, 32)  # Hidden layer
        self.fc3 = nn.Linear(32, len(np.unique(y)))  # Output layer

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = SimpleFCN()

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    # Lists to keep track of loss and accuracy
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        # Variables to store performance metrics
        train_loss = 0
        train_correct = 0
        train_total = 0
        val_loss = 0
        val_correct = 0
        val_total = 0

        # Training phase
        model.train()
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()

        # Calculate training loss and accuracy
        train_loss /= len(train_loader.dataset)
        train_accuracy = 100 * train_correct / train_total
        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)

        # Validation phase
        model.eval()
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        # Calculate validation loss and accuracy
        val_loss /= len(val_loader.dataset)
        val_accuracy = 100 * val_correct / val_total
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

        # Print the epoch's results
        print(f'Epoch {epoch + 1}: Training Loss = {train_loss:.4f}, Training Accuracy = {train_accuracy:.2f}%, Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.2f}%')

    return train_losses, train_accuracies, val_losses, val_accuracies

def evaluate_model(model, test_loader, criterion):
    model.eval()
    test_loss = 0
    all_predictions = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            all_predictions.extend(predicted.cpu().numpy())  # Collect all predictions
            all_labels.extend(labels.cpu().numpy())  # Collect all true labels

    test_loss /= len(test_loader.dataset)
    accuracy = 100 * np.sum(np.array(all_labels) == np.array(all_predictions)) / len(all_labels)
    precision = precision_score(all_labels, all_predictions, average='macro')
    recall = recall_score(all_labels, all_predictions, average='macro')
    f1 = f1_score(all_labels, all_predictions, average='macro')
    conf_matrix = confusion_matrix(all_labels, all_predictions)
    class_report = classification_report(all_labels, all_predictions)

    return test_loss, accuracy, precision, recall, f1, conf_matrix, class_report

# Call to train the model with validation
train_losses, train_accuracies, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25)

# Plotting
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.legend()

plt.show()

test_loss, test_accuracy, test_precision, test_recall, test_f1, test_conf_matrix, test_class_report = evaluate_model(model, test_loader, criterion)

print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.2f}%")
print("Precision: {:.2f}".format(test_precision))
print("Recall: {:.2f}".format(test_recall))
print("F1-Score: {:.2f}".format(test_f1))
print("\nConfusion Matrix:\n", test_conf_matrix)
print("\nClassification Report:\n", test_class_report)

# Plot normalized confusion matrix
conf_matrix_norm = test_conf_matrix.astype('float') / test_conf_matrix.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix_norm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Normalized Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation=45)
plt.yticks(tick_marks, classes)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

"""## CNN"""

class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3)
        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)
        self.fc1 = nn.Linear(in_features=64 * 8, out_features=128)  # Adjust input size based on the actual tensor size
        self.fc2 = nn.Linear(in_features=128, out_features=6)  # Assuming 6 classes

    def forward(self, x):
        x = F.relu(self.conv1(x))
        print(x.size())  # Print size of tensor after conv1
        x = F.relu(self.conv2(x))
        print(x.size())  # Print size of tensor after conv2
        x = x.view(x.size(0), -1)  # Flatten the tensor
        print(x.size())  # Print size of tensor after flattening
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Initialize the model
model = CNNModel()

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training the model
num_epochs = 25
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    correct_train = 0
    total_train = 0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        inputs = inputs.unsqueeze(1)  # Add a channel dimension
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)
        _, predicted_train = torch.max(outputs, 1)
        total_train += labels.size(0)
        correct_train += (predicted_train == labels).sum().item()

    # Calculate training accuracy
    train_accuracy = correct_train / total_train

    # Validate the model
    model.eval()
    val_loss = 0.0
    correct_val = 0
    total_val = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.unsqueeze(1)  # Add a channel dimension
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
            _, predicted_val = torch.max(outputs, 1)
            total_val += labels.size(0)
            correct_val += (predicted_val == labels).sum().item()

    # Calculate validation accuracy
    val_accuracy = correct_val / total_val

    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader.dataset)}, Train Accuracy: {train_accuracy * 100:.2f}%, Val Loss: {val_loss/len(val_loader.dataset)}, Val Accuracy: {val_accuracy * 100:.2f}%")

# Plot training and validation loss
plt.figure(figsize=(8, 4))
plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')
plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plot training and validation accuracy
plt.figure(figsize=(8, 4))
plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')
plt.plot(range(1, num_epochs + 1), val_accuracies, label='Val Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

# Evaluate the model on the test set
model.eval()
test_predictions = []
true_labels = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs = inputs.unsqueeze(1)  # Add a channel dimension
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        test_predictions.extend(predicted.tolist())
        true_labels.extend(labels.tolist())

# Calculate accuracy, precision, recall, and F1-score
test_accuracy = accuracy_score(true_labels, test_predictions)
precision = precision_score(true_labels, test_predictions, average='weighted')
recall = recall_score(true_labels, test_predictions, average='weighted')
f1 = f1_score(true_labels, test_predictions, average='weighted')

# Generate confusion matrix and classification report
conf_matrix = confusion_matrix(true_labels, test_predictions)
class_report = classification_report(true_labels, test_predictions)

print(f"\nTest Accuracy: {test_accuracy * 100:.2f}%")
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("\nConfusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(class_report)

# Plot normalized confusion matrix
conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix_norm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Normalized Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation=45)
plt.yticks(tick_marks, classes)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

"""## RNN"""

class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(SimpleRNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        # Initialize hidden state
        # Ensure that x has dimensions: [batch_size, seq_length, features]
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)

        # Forward propagate RNN
        out, _ = self.rnn(x, h0)  # x should be correctly shaped

        # Decode the hidden state of the last time step
        out = self.fc(out[:, -1, :])
        return out

# Assuming each sample in X_train should be (seq_length, num_features)
# Make sure to reshape or adjust your data preprocessing to match this requirement
print("Shape of a single batch input:", next(iter(train_loader))[0].shape)

X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)

X_val_tensor = torch.tensor(X_val, dtype=torch.float32)
y_val_tensor = torch.tensor(y_val, dtype=torch.long)

X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.long)

# Assuming you have the data in tensors but not shaped correctly:
X_train_tensor = X_train_tensor.reshape(-1, 1, 12)  # Reshape with seq_length = 1
X_val_tensor = X_val_tensor.reshape(-1, 1, 12)
X_test_tensor = X_test_tensor.reshape(-1, 1, 12)

# Recreate DataLoaders with the reshaped data
train_data = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)

val_data = TensorDataset(X_val_tensor, y_val_tensor)
val_loader = DataLoader(val_data, batch_size=64, shuffle=False)

test_data = TensorDataset(X_test_tensor, y_test_tensor)
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)

train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)

def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            train_correct += (predicted == labels).sum().item()
            train_total += labels.size(0)

        train_loss /= len(train_loader.dataset)
        train_accuracy = 100 * train_correct / train_total
        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)

        # Validation phase
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs, 1)
                val_correct += (predicted == labels).sum().item()
                val_total += labels.size(0)

        val_loss /= len(val_loader.dataset)
        val_accuracy = 100 * val_correct / val_total
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

        print(f'Epoch {epoch+1}: Training Loss = {train_loss:.4f}, Training Accuracy = {train_accuracy:.2f}%, Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.2f}%')

    return train_losses, train_accuracies, val_losses, val_accuracies

def evaluate_model(model, test_loader, criterion):
    model.eval()
    test_loss = 0
    correct = 0
    total = 0
    all_labels = []
    all_predictions = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    test_loss /= len(test_loader.dataset)
    accuracy = 100 * correct / total
    precision = precision_score(all_labels, all_predictions, average='macro')
    recall = recall_score(all_labels, all_predictions, average='macro')
    f1 = f1_score(all_labels, all_predictions, average='macro')
    conf_matrix = confusion_matrix(all_labels, all_predictions)
    class_report = classification_report(all_labels, all_predictions)

    return test_loss, accuracy, precision, recall, f1, conf_matrix, class_report

input_size = 12  # Number of features per time step in the input
hidden_size = 50  # Number of features in the hidden state
num_layers = 2  # Number of recurrent layers
num_classes = len(np.unique(y_train))  # Number of output classes

model = SimpleRNN(input_size, hidden_size, num_layers, num_classes=num_classes)

optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

# Train the model
train_losses, train_accuracies, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)

plt.figure(figsize=(12, 6))

# Plot training and validation losses
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot training and validation accuracies
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()

plt.show()

test_loss, test_accuracy, test_precision, test_recall, test_f1, test_conf_matrix, test_class_report = evaluate_model(model, test_loader, criterion)

print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.2f}%")
print("Precision: {:.2f}".format(test_precision))
print("Recall: {:.2f}".format(test_recall))
print("F1-Score: {:.2f}".format(test_f1))
print("\nConfusion Matrix:\n", test_conf_matrix)
print("\nClassification Report:\n", test_class_report)

# Plot normalized confusion matrix
conf_matrix_norm = test_conf_matrix.astype('float') / test_conf_matrix.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix_norm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Normalized Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation=45)
plt.yticks(tick_marks, classes)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

"""## LSTM"""

class SimpleLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(SimpleLSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)  # Output layer

    def forward(self, x):
        # Initialize hidden and cell states
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)

        # Forward propagate LSTM
        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)

        # Decode the hidden state of the last time step
        out = self.fc(out[:, -1, :])
        return out

input_size = 12  # Number of features per time step
hidden_size = 50  # Number of features in the hidden state
num_layers = 1  # Number of LSTM layers
num_classes = len(np.unique(y_train))  # Assuming you have defined y_train earlier

model = SimpleLSTM(input_size, hidden_size, num_layers, num_classes)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            train_correct += (predicted == labels).sum().item()
            train_total += labels.size(0)

        train_loss /= len(train_loader.dataset)
        train_accuracy = 100 * train_correct / train_total
        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)

        # Validation phase
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs, 1)
                val_correct += (predicted == labels).sum().item()
                val_total += labels.size(0)

        val_loss /= len(val_loader.dataset)
        val_accuracy = 100 * val_correct / val_total
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

        print(f'Epoch {epoch+1}: Training Loss = {train_loss:.4f}, Training Accuracy = {train_accuracy:.2f}%, Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.2f}%')

    return train_losses, train_accuracies, val_losses, val_accuracies

def evaluate_model(model, test_loader, criterion):
    model.eval()
    test_loss = 0
    correct = 0
    total = 0
    all_labels = []
    all_predictions = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    test_loss /= len(test_loader.dataset)
    accuracy = 100 * correct / total
    precision = precision_score(all_labels, all_predictions, average='macro')
    recall = recall_score(all_labels, all_predictions, average='macro')
    f1 = f1_score(all_labels, all_predictions, average='macro')
    conf_matrix = confusion_matrix(all_labels, all_predictions)
    class_report = classification_report(all_labels, all_predictions)

    return test_loss, accuracy, precision, recall, f1, conf_matrix, class_report

train_losses, train_accuracies, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50)

plt.figure(figsize=(12, 6))

# Plot training and validation losses
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot training and validation accuracies
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()

plt.show()

test_loss, test_accuracy, test_precision, test_recall, test_f1, test_conf_matrix, test_class_report = evaluate_model(model, test_loader, criterion)

print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%")
print("Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}".format(test_precision, test_recall, test_f1))
print("\nConfusion Matrix:\n", test_conf_matrix)
print("\nClassification Report:\n", test_class_report)

# Plot normalized confusion matrix
conf_matrix_norm = test_conf_matrix.astype('float') / test_conf_matrix.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix_norm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Normalized Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation=45)
plt.yticks(tick_marks, classes)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

"""## TF"""

class TransformerModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_heads, num_classes, dropout=0.5):
        super(TransformerModel, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size  # Ensure this is defined as an instance variable
        self.num_layers = num_layers
        self.num_heads = num_heads

        # Embedding layer that expands the input features to the hidden size
        self.embedding = nn.Linear(input_size, hidden_size)
        # Transformer Encoder Layer
        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)
        # Fully connected layer to map the encoded features to the output classes
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, src):
        # Embed input features to hidden size and apply scaling for stability
        src = self.embedding(src)
        src *= torch.sqrt(torch.tensor(float(self.hidden_size)))  # Make sure to cast hidden_size to float if needed
        output = self.transformer_encoder(src)

        # Use the output of the last token from the sequence
        if output.dim() == 3 and output.size(1) > 0:
            output = output[:, -1, :]
        output = self.fc(output)
        return output

# Example assuming you have your data ready in the form [batch_size, seq_length, features]
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)

X_val_tensor = torch.tensor(X_val, dtype=torch.float32)
y_val_tensor = torch.tensor(y_val, dtype=torch.long)

X_val_tensor = torch.tensor(X_test, dtype=torch.float32)
y_val_tensor = torch.tensor(y_test, dtype=torch.long)

# Assuming the input data is shaped as [batch_size, features]
X_train_tensor = X_train_tensor.unsqueeze(1)  # Add sequence length dimension
X_val_tensor = X_val_tensor.unsqueeze(1)
X_test_tensor = X_test_tensor.unsqueeze(1)

X_test_tensor = X_test_tensor.squeeze(1)

# Make sure the DataLoader is set up to handle this correctly
train_data = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)

val_data = TensorDataset(X_val_tensor, y_val_tensor)
val_loader = DataLoader(val_data, batch_size=64, shuffle=False)

test_data = TensorDataset(X_test_tensor, y_test_tensor)
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)

input_size = 12
hidden_size = 512
num_layers = 4
num_heads = 8
num_classes = len(sampled_df['Dx'].unique())
dropout = 0.1

model = TransformerModel(input_size, hidden_size, num_layers, num_heads, num_classes, dropout)

optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
criterion = nn.CrossEntropyLoss()

def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            train_correct += (predicted == labels).sum().item()
            train_total += labels.size(0)

        train_loss /= len(train_loader.dataset)
        train_accuracy = 100 * train_correct / train_total
        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)

        # Validation phase
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs, 1)
                val_correct += (predicted == labels).sum().item()
                val_total += labels.size(0)

        val_loss /= len(val_loader.dataset)
        val_accuracy = 100 * val_correct / val_total
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

        print(f'Epoch {epoch+1}: Training Loss = {train_loss:.4f}, Training Accuracy = {train_accuracy:.2f}%, Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.2f}%')

    return train_losses, train_accuracies, val_losses, val_accuracies

def evaluate_model(model, test_loader, criterion):
    model.eval()
    test_loss = 0
    correct = 0  # Initialize the correct predictions counter
    total = 0  # Initialize the total predictions counter
    all_labels = []
    all_predictions = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()  # Sum correct predictions
            total += labels.size(0)  # Count total samples
            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    test_loss /= len(test_loader.dataset)
    accuracy = 100 * correct / total  # Calculate accuracy
    precision = precision_score(all_labels, all_predictions, average='macro')
    recall = recall_score(all_labels, all_predictions, average='macro')
    f1 = f1_score(all_labels, all_predictions, average='macro')
    conf_matrix = confusion_matrix(all_labels, all_predictions)
    class_report = classification_report(all_labels, all_predictions)

    return test_loss, accuracy, precision, recall, f1, conf_matrix, class_report

train_losses, train_accuracies, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25)

plt.figure(figsize=(12, 6))

# Plot training and validation losses
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot training and validation accuracies
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()

plt.show()

test_loss, test_accuracy, test_precision, test_recall, test_f1, test_conf_matrix, test_class_report = evaluate_model(model, test_loader, criterion)

print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%")
print("Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}".format(test_precision, test_recall, test_f1))
print("\nConfusion Matrix:\n", test_conf_matrix)
print("\nClassification Report:\n", test_class_report)

# Plot normalized confusion matrix
conf_matrix_norm = test_conf_matrix.astype('float') / test_conf_matrix.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix_norm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Normalized Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation=45)
plt.yticks(tick_marks, classes)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

"""## Comparison"""

models = ['ANN', 'FCN', 'CNN', 'RNN', 'LSTM', 'TF']
accuracies = [72.12, 74.04, 75.00, 64.42, 70.19, 56.73]

plt.figure(figsize=(10, 6))  # Set the figure size for better readability
bars = plt.bar(models, accuracies, color='red')  # Create a bar graph

# Add text annotations above the bars
for bar in bars:
    yval = bar.get_height()  # Get the height of the bar
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5,  # Position the text above the bar
             f'{yval}%',  # Text to display (formatted to show percentage)
             ha='center', va='bottom')  # Center-align the text

plt.xlabel('Model')  # Label on X-axis
plt.ylabel('Accuracy (%)')  # Label on Y-axis
plt.title('Comparison of Model Accuracies')  # Title of the graph
plt.ylim([50, 80])  # Set the Y-axis limits to focus on the range of interest
plt.show()  # Display the graph

confusion_matrix = np.array([
    [16, 1, 0, 0, 1, 1],
    [0, 12, 1, 1, 0, 0],
    [4, 1, 5, 1, 1, 2],
    [0, 0, 0, 7, 1, 0],
    [4, 0, 1, 0, 20, 1],
    [1, 1, 2, 0, 1, 18]
])
'atrial fibrillation', 'st depression', 'ventricular ectopics', 'left bundle branch block', 'right bundle branch block', 'sinus rhythm'

# Normalize by row
row_sums = confusion_matrix.sum(axis=1)
norm_conf_matrix = confusion_matrix / row_sums[:, np.newaxis]

print(norm_conf_matrix)

plt.figure(figsize=(10, 8))
ax = sns.heatmap(norm_conf_matrix, annot=True, cmap='Blues', fmt=".2f", cbar_kws={'label': 'Normalized Frequency'})
plt.title('Normalized Confusion Matrix')
plt.ylabel('True Labels')
plt.xlabel('Predicted Labels')

# Optional: Customize the xticks and yticks labels if you have specific class names
class_labels = ['atrial fibrillation', 'st depression', 'ventricular ectopics', 'left bundle branch block', 'right bundle branch block', 'sinus rhythm']
plt.xticks(np.arange(len(class_labels)) + 0.5, class_labels, rotation=45, ha="right")
plt.yticks(np.arange(len(class_labels)) + 0.5, class_labels, rotation=0, va="center")

plt.show()

"""## AlexNet"""

# Define the input shape
input_shape = (1038, 12)

# Define the AlexNet model
alexNet_model = Sequential([
    Conv1D(filters=96, kernel_size=11, strides=4, activation='relu', input_shape=input_shape),
    MaxPooling1D(pool_size=2, strides=2),
    BatchNormalization(),

    Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'),
    MaxPooling1D(pool_size=2, strides=2),
    BatchNormalization(),

    Conv1D(filters=384, kernel_size=3, padding='same', activation='relu'),
    Conv1D(filters=384, kernel_size=3, padding='same', activation='relu'),
    Conv1D(filters=256, kernel_size=3, padding='same', activation='relu'),
    MaxPooling1D(pool_size=2, strides=2),
    BatchNormalization(),

    Flatten(),

    Dense(4096, activation='relu'),
    Dropout(0.5),
    Dense(4096, activation='relu'),
    Dropout(0.5),
    Dense(27, activation='sigmoid')
])

# Compile the model
alexNet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.AUC()])

# Display the model summary
alexNet_model.summary()

# Train the model
history = alexNet_model.fit(
    X_train_reshaped, y_train_split,
    batch_size=64,
    epochs=10,
    validation_data=(X_val_reshaped, y_val_split)
)

# Split X_train into training and validation sets
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Reshape the training and validation data
X_train_reshaped = X_train_split.values.reshape(-1, 12)
X_val_reshaped = X_val_split.values.reshape(-1, 12)

# Ensure that the number of samples in X_train_reshaped matches y_train
assert X_train_reshaped.shape[0] == y_train_split.shape[0]

# Calculate the number of samples for the validation set
val_size = int(0.2 * len(X_train))

# Split X_train into training and validation sets
X_train_split, X_val_split = X_train[:len(X_train)-val_size], X_train[len(X_train)-val_size:]

# Reshape the training and validation data
X_train_reshaped = X_train_split.values.reshape(-1, 12)
X_val_reshaped = X_val_split.values.reshape(-1, 12)

# Reshape input data to match the expected shape of the model
X_train_reshaped = X_train.values.reshape(-1, 1038, 12)
X_val_reshaped = X_val.values.reshape(-1, 1038, 12)

X_train.values.shape
#X_val.values.shape

# Initialize the model
alexNet_model = Sequential()

# Add layers
alexNet_model.add(Conv1D(filters=96, kernel_size=11, strides=4, input_shape=(12, 1)))  # Input shape modified
alexNet_model.add(BatchNormalization())
alexNet_model.add(Activation('relu'))
alexNet_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))

alexNet_model.add(Conv1D(filters=256, kernel_size=5, padding='same'))
alexNet_model.add(BatchNormalization())
alexNet_model.add(Activation('relu'))
alexNet_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))

alexNet_model.add(Conv1D(filters=384, padding='same', kernel_size=3))
alexNet_model.add(BatchNormalization())
alexNet_model.add(Activation('relu'))
alexNet_model.add(Conv1D(filters=384, kernel_size=3, padding='same'))
alexNet_model.add(BatchNormalization())
alexNet_model.add(Activation('relu'))
alexNet_model.add(Conv1D(filters=256, kernel_size=3, input_shape=(1, 384)))
alexNet_model.add(BatchNormalization())
alexNet_model.add(Activation('relu'))
alexNet_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))

alexNet_model.add(GlobalAveragePooling1D())
alexNet_model.add(Dense(128, activation='relu'))
alexNet_model.add(Dropout(0.4))
alexNet_model.add(Dense(128, activation='relu'))
alexNet_model.add(Dropout(0.4))
alexNet_model.add(Dense(27, activation='sigmoid'))  # Assuming 27 classes for 'Dx_encoded'

# Compile the model
alexNet_model.compile(loss='binary_crossentropy', optimizer='adam',
                      metrics=['accuracy', 'recall', 'precision', 'AUC'])

# Print model summary
alexNet_model.summary()

# Compile the model
alexNet_model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[
        tf.keras.metrics.BinaryAccuracy(name='accuracy'),
        tf.keras.metrics.Recall(name='recall'),
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.F1Score(name='f1_score'),
        tf.keras.metrics.AUC(name='auc')
    ]
)

X_train_reshaped = X_train.values.reshape(-1, 1038, 12)
X_val_reshaped = X_val.values.reshape(-1, 1038, 12)
X_test_reshaped = X_test.values.reshape(-1, 1038, 12)

# Check the shape of your DataFrame
print("Shape of the DataFrame:", sampled_df.shape)

# Get the length of each time series for the 12 features
length_of_time_series = sampled_df.shape[0]  # Assuming each row represents a time point
print("Length of each time series for the 12 features:", length_of_time_series)

# Convert DataFrame to NumPy array and reshape
X_reshaped = np.array(X).reshape(-1, 1038, 12)

# Check the shape of the reshaped input data
print("Shape of the reshaped input data:", X_reshaped.shape)

# Split the data into training, validation, and testing sets
X_train, X_temp, y_train, y_temp = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Train the model
history = alexNet_model.fit(
    X_train, y_train,
    batch_size=64,
    epochs=10,
    validation_data=(X_val, y_val)
)

# Define your batch generator
class MyDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        # Convert pandas Series to numpy array and then to tensor
        x = torch.tensor(self.X.iloc[idx].values, dtype=torch.float32)
        y = torch.tensor(self.y.iloc[idx], dtype=torch.long)
        return x, y

class AlexNet(nn.Module):
    def __init__(self, num_classes=27):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv1d(in_channels=12, out_channels=96, kernel_size=11, stride=4),
            nn.BatchNorm1d(96),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2, padding='same'),

            nn.Conv1d(in_channels=96, out_channels=256, kernel_size=5, padding='same'),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2, padding='same'),

            nn.Conv1d(in_channels=256, out_channels=384, kernel_size=3, padding='same'),
            nn.BatchNorm1d(384),
            nn.ReLU(inplace=True),
            nn.Conv1d(in_channels=384, out_channels=384, kernel_size=3, padding='same'),
            nn.BatchNorm1d(384),
            nn.ReLU(inplace=True),
            nn.Conv1d(in_channels=384, out_channels=256, kernel_size=3, padding='same'),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2, padding='same')
        )

        self.avgpool = nn.AdaptiveAvgPool1d(1)

        self.classifier = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(128, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(128, num_classes),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# Define your dataset and dataloaders
train_dataset = MyDataset(X, y)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# Reshape input tensors to have the correct shape
X_train_dense = X_train_tensor.unsqueeze(1).unsqueeze(-1)
X_val_dense = X_val_tensor.unsqueeze(1).unsqueeze(-1)
X_test_dense = X_test_tensor.unsqueeze(1).unsqueeze(-1)

# Initialize the model
model = AlexNet()

# Define loss function and optimizer
criterion = nn.BCELoss()
# Define scheduler
scheduler = ReduceLROnPlateau(optimizer, 'min')
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training the model
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    correct_train = 0
    total_train = 0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        inputs = inputs.unsqueeze(1)  # Add a channel dimension
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)
        _, predicted = torch.max(outputs, 1)
        correct_train += (predicted == labels).sum().item()
        total_train += labels.size(0)

    # Calculate training accuracy
    train_accuracy = correct_train / total_train

    # Validate the model
    model.eval()
    val_loss = 0.0
    correct_val = 0
    total_val = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.unsqueeze(1)  # Add a channel dimension
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            correct_val += (predicted == labels).sum().item()
            total_val += labels.size(0)

    # Calculate validation accuracy
    val_accuracy = correct_val / total_val

    # Print progress
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader.dataset)}, Val Loss: {val_loss/len(val_loader.dataset)}, Train Accuracy: {train_accuracy}, Val Accuracy: {val_accuracy}")

# Define number of epochs
num_epochs = 10

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)
    epoch_loss = running_loss / len(train_dataset)

    # You can calculate validation loss and metrics similarly

    # Update learning rate scheduler
    scheduler.step(epoch_loss)

    # Print epoch statistics
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')

# Plot training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs + 1), train_loss_history, label='Train Loss')
plt.plot(range(1, num_epochs + 1), val_loss_history, label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plot training and validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs + 1), train_acc_history, label='Train Accuracy')
plt.plot(range(1, num_epochs + 1), val_acc_history, label='Val Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

# Evaluation on the test set
model.eval()
predictions = []
true_labels = []
with torch.no_grad():
    for inputs, labels in test_loader:
        outputs = model(inputs.permute(0, 2, 1))  # Permute input for Conv1d
        _, predicted = torch.max(outputs, 1)
        predictions.extend(predicted.tolist())
        true_labels.extend(labels.tolist())

# Calculate metrics
accuracy = accuracy_score(true_labels, predictions)
precision = precision_score(true_labels, predictions, average='weighted')
recall = recall_score(true_labels, predictions, average='weighted')
f1 = f1_score(true_labels, predictions, average='weighted')
conf_matrix = confusion_matrix(true_labels, predictions)
class_report = classification_report(true_labels, predictions)

print(f"Test Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

"""## Lenet"""

class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.conv1 = nn.Conv1d(12, 6, kernel_size=5)  # Input channels: 12, Output channels: 6
        self.conv2 = nn.Conv1d(6, 16, kernel_size=5)  # Input channels: 6, Output channels: 16
        self.fc1 = nn.Linear(16 * 122, 120)  # 16 channels * remaining input size after max pooling
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)  # 10 output classes

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool1d(x, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool1d(x, 2)
        x = x.view(-1, 16 * 122)  # Adjusted input size
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Initialize the model
model = LeNet5()

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs.permute(0, 2, 1))  # Permute input for Conv1d
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")

# Training loop
num_epochs = 50
for epoch in range(num_epochs):
    model.train()  # Set the model to training mode
    train_loss = 0.0
    correct = 0
    total = 0
    # Training loop
    for inputs, labels in train_loader:
        optimizer.zero_grad()

        # Add a channel dimension to the input tensor
        inputs = inputs.unsqueeze(1)
        # Repeat the input tensor along the channel dimension to match the expected number of channels
        inputs = inputs.repeat(1, 12, 1)

        # Forward pass
        outputs = model(inputs)

        # Calculate loss
        loss = criterion(outputs, labels)

        # Backward pass
        loss.backward()

        # Update weights
        optimizer.step()

    # Validation loop
    model.eval()  # Set the model to evaluation mode
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs.permute(0, 2, 1))  # Permute input for Conv1d
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    val_loss /= len(val_loader)
    val_accuracy = 100.0 * correct / total

    # Print training and validation metrics
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, "
          f"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%")

print(inputs.shape)

"""## VGG-16"""

# Define the VGG-16 model
class VGG16(nn.Module):
    def __init__(self, num_classes=10):
        super(VGG16, self).__init__()
        self.features = nn.Sequential(
            nn.Conv1d(12, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Conv1d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Conv1d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Conv1d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool1d(7)
        self.classifier = nn.Sequential(
            nn.Linear(512 * 7, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# Instantiate the VGG-16 model
model = VGG16(num_classes=10)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        inputs = inputs.unsqueeze(1)
        outputs = model(inputs)  # Permute input for Conv1d
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")